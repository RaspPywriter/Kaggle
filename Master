# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load in 

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the "../input/" directory.
# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory

import os
print(os.listdir("../input"))
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC, LinearSVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import Perceptron
from sklearn.linear_model import SGDClassifier
from sklearn.tree import DecisionTreeClassifier

# Any results you write to the current directory are saved as output.
#played with gender submission file
gender_data = pd.read_csv('../input/gender_submission.csv')
gender_data.head()
#get info about the data
gender_data.info()
train_data = pd.read_csv('../input/train.csv')
#show first 5 rows
train_data.head()
#some sample queries that didn't work
#train_data['Name'].value_counts() - useless because unique
#train_data['Ticket'].value_counts() - highest # is 7
#value count to see how many there are of each (can check if important values are balanced or not)
train_data['Pclass'].value_counts()
train_data['Pclass'].describe()
train_data['Sex'].value_counts()
train_data['Sex'].describe()
t = train_data['Age'].value_counts()
#get the top 30 values by count
t.nlargest(30)
train_data['SibSp'].describe()
sib = train_data['SibSp'].value_counts()
train_data['Parch'].describe()
train_data['Parch'].value_counts()
train_data['Ticket'].describe()
ticket = train_data['Ticket'].value_counts()
ticket.nlargest(30)
train_data['Fare'].describe()
fare = train_data['Fare'].value_counts()
fare.nlargest(25)
train_data['Cabin'].describe()
cabin = train_data['Cabin'].value_counts()
cabin.nlargest(20)
train_data['Embarked'].describe()
train_data['Survived'].mean()   
train_data = train_data.drop(['Cabin', 'Fare'], axis=1)
train_data = train_data.drop(['Ticket'], axis=1)
train_data = train_data.drop(['PassengerId'], axis=1)
train_data = train_data.drop(['Embarked'], axis=1)
train_data = train_data.drop(['Name'], axis=1)
train_data[["Sex", "Survived"]].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)
train_data.dropna(how='any', inplace=True)
X_train = train_data.drop(['Survived'], axis=1)
train_data.loc[train_data['Sex'] == 'male', 'Sex'] = 0
#map male to 0
train_data.loc[train_data['Sex'] == 'female', 'Sex'] = 1
#map female to 1
train_data.loc[train_data['Sex'] == 'female', 'Sex'] = 1
#set Y_train to the labels
Y_train = train_data["Survived"]
X_train.describe()
test_data = pd.read_csv('../input/test.csv')
test_data.head()
test_data  = test_data.drop(['Name'], axis=1)
test_data  = test_data.drop(['Ticket'], axis=1)
test_data = test_data.drop(['Cabin'], axis=1)
test_data = test_data.drop(['Embarked'], axis=1)
test_data = test_data.drop(['Fare'], axis=1)
#change m/f for test
test_data.loc[test_data['Sex'] == 'male', 'Sex'] = 0
test_data.loc[test_data['Sex'] == 'female', 'Sex'] = 1
#fill in avg age
test_data['Age']= test_data['Age'].fillna('30.2')
X_train.loc[X_train['Sex'] == 'male', 'Sex'] = 0
X_train.loc[X_train['Sex'] == 'female', 'Sex'] = 1
X_train.shape, Y_train.shape, test_data.shape
logreg = LogisticRegression()
logreg.fit(X_train, Y_train)

Y_pred = logreg.predict(test_data)
print(Y_pred)
acc_log = round(logreg.score(X_train, Y_train) * 100, 2)
acc_log
